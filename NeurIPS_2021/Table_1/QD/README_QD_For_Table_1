This is the code for QD method used for our comparison which was adjusted from the original QD code (also included in the upper level folder) or you can find it at https://github.com/TeaPearce/Deep_Learning_Prediction_Intervals

All of our experiments on QD method with UCI datasets were conducted on a single Ubuntu workstation, and we use Intel I9-10980xe CPU generated all the results instead of using a GPU because the training are relatively fast on CPU.

To reproduce the results, simply assign the data set name to the "data_name" variable at the beginning of this code before running the main file.

Accepted data names are: 'boston', 'concrete', 'energy', 'kin8nm', 'naval', 'power', 'protein', 'wine', 'yacht', 'MSD'
The results will be generated in the ./Results_QD/ including the summary of the training results (.txt files), plotted loss curves (./Results/loss_curves/) and loss history for each case (.csv format in ./Results/loss_history/)

We also prepared pre-generated results for your reference (in ./Pre_generated_results/)

The results for QD method from our Table 1 can be obtained by running this code or using our pre-generated results.

The hyper-parameters for 'boston' and 'concrete' cases are given from the original QD paper/code. They are not provided for the rest of 8 data sets, we took the hyper-parameters from 'concrete' case and applied to all of the 8 data sets, except for 'MSD' case that we run 20 epochs instead of 800.

Have fun!
